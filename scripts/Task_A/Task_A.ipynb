{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f37f49de",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Task A: Supplier Data Cleaning and Joining\n",
    "Vanilla Steel Junior Data Scientist Assessment\n",
    "\n",
    "This script cleans and merges two supplier datasets into a unified inventory dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6278b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1e162ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load both supplier datasets from Excel files.\"\"\"\n",
    "    # Define paths\n",
    "    resources_dir = Path(\"../../resources/task_1\")\n",
    "    \n",
    "    # Load data\n",
    "    supplier1_df = pd.read_excel(resources_dir / \"supplier_data1.xlsx\")\n",
    "    supplier2_df = pd.read_excel(resources_dir / \"supplier_data2.xlsx\")\n",
    "    \n",
    "    return supplier1_df, supplier2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9cd80960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_supplier1(df):\n",
    "    \"\"\"\n",
    "    Clean and standardize supplier_data1.xlsx\n",
    "    \n",
    "    Assumptions:\n",
    "    - Quality/Choice: Standardize to numeric (1, 2, 3) from (1st, 2nd, 3rd)\n",
    "    - Grade: Standardize format by removing extra spaces and converting to uppercase\n",
    "    - Finish: Standardize German terms to English equivalents\n",
    "    - Thickness and Width: Already in mm, ensure float format\n",
    "    - Description: Clean and standardize defect descriptions\n",
    "    - Gross weight: Rename to Weight for consistency with supplier2\n",
    "    - RP02, RM, AG, AI: Technical properties, keep as is but handle zeros\n",
    "    - Quantity: Keep as is, handling any missing values\n",
    "    \"\"\"\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Standardize Quality/Choice to numeric\n",
    "    quality_map = {'1st': 1, '2nd': 2, '3rd': 3}\n",
    "    df_clean['Quality'] = df_clean['Quality/Choice'].map(quality_map)\n",
    "    df_clean.drop('Quality/Choice', axis=1, inplace=True)\n",
    "    \n",
    "    # Standardize Grade (uppercase, trim)\n",
    "    df_clean['Grade'] = df_clean['Grade'].str.strip().str.upper()\n",
    "    \n",
    "    # Standardize Finish (translate German to English)\n",
    "    finish_map = {\n",
    "        'ungebeizt': 'unpickled',\n",
    "        'gebeizt': 'pickled', \n",
    "        'gebeizt und geglüht': 'pickled and annealed',\n",
    "        'geglüht': 'annealed'\n",
    "    }\n",
    "    df_clean['Finish'] = df_clean['Finish'].replace(finish_map)\n",
    "\n",
    "    # Standardize Description (translate German to English)\n",
    "    description_map = {\n",
    "    'Kantenfehler - FS-Kantenrisse': 'Edge defect – FS edge cracks',\n",
    "    'Längs- oder Querisse': 'Longitudinal or transverse cracks',\n",
    "    'Sollmasse (Gewicht) unterschritten': 'Target weight not reached'\n",
    "    }\n",
    "    df_clean['Description'] = df_clean['Description'].replace(description_map)\n",
    "\n",
    "    # Rename columns for consistency\n",
    "    rename_map = {\n",
    "        'Thickness (mm)': 'Thickness_mm',\n",
    "        'Width (mm)': 'Width_mm',\n",
    "        'Gross weight (kg)': 'Weight_kg',\n",
    "    }\n",
    "    df_clean.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    # Ensure all numeric columns are float\n",
    "    numeric_cols = ['Thickness_mm', 'Width_mm', 'Weight_kg',\n",
    "                    'RP02', 'RM', 'Quantity', 'AG', 'AI']\n",
    "    for col in numeric_cols:\n",
    "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').astype(float)\n",
    "    \n",
    "    # Handle zeros in technical properties (0 might mean not tested/applicable)\n",
    "    # Replace 0 with NaN for technical properties\n",
    "    tech_props = ['RP02', 'RM', 'AG', 'AI']\n",
    "    for col in tech_props:\n",
    "        df_clean[col] = df_clean[col].replace(0, np.nan)\n",
    "    \n",
    "    # Add source identifier\n",
    "    df_clean['Source'] = 'Supplier1'\n",
    "    \n",
    "    # Reorder columns for clarity\n",
    "    column_order = ['Source', 'Grade', 'Quality', 'Finish', 'Thickness_mm', \n",
    "                   'Width_mm', 'Weight_kg', 'Quantity', 'Description',\n",
    "                   'RP02', 'RM', 'AG', 'AI']\n",
    "    df_clean = df_clean[column_order]\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aabe078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_supplier2(df):\n",
    "    \"\"\"\n",
    "    Clean and standardize supplier_data2.xlsx\n",
    "    \n",
    "    Assumptions:\n",
    "    - Material: Parse to extract base grade and coating information\n",
    "    - Description: Standardize surface treatment descriptions\n",
    "    - Article ID: Keep as unique identifier\n",
    "    - Weight: Already in kg, consistent with supplier1\n",
    "    - Quantity: Keep as is\n",
    "    - Reserved: Convert to boolean (True if reserved, False if not)\n",
    "    \"\"\"\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Parse Material column to extract grade and coating\n",
    "    def parse_material(material):\n",
    "        \"\"\"Extract base grade and coating from material string.\"\"\"\n",
    "        if pd.isna(material):\n",
    "            return None, None\n",
    "        \n",
    "        material = str(material).strip()\n",
    "        \n",
    "        # Check for coating patterns (+Z, +AZ, etc.)\n",
    "        if '+' in material:\n",
    "            parts = material.split('+')\n",
    "            grade = parts[0].strip()\n",
    "            coating = '+' + parts[1].strip()\n",
    "        else:\n",
    "            grade = material\n",
    "            coating = None\n",
    "            \n",
    "        return grade, coating\n",
    "    \n",
    "    # Apply parsing\n",
    "    df_clean[['Grade', 'Coating']] = df_clean['Material'].apply(\n",
    "        lambda x: pd.Series(parse_material(x))\n",
    "    )\n",
    "    \n",
    "    # Standardize grade format\n",
    "    df_clean['Grade'] = df_clean['Grade'].str.strip().str.upper()\n",
    "    \n",
    "    # Standardize Description to match Finish concept\n",
    "    description_map = {\n",
    "        'Material is Oiled': 'oiled',\n",
    "        'Material is Painted': 'painted',\n",
    "        'Material is not Oiled': 'not oiled'\n",
    "    }\n",
    "    df_clean['Finish'] = df_clean['Description'].replace(description_map)\n",
    "    \n",
    "    # Convert Reserved to boolean\n",
    "    df_clean['Reserved'] = df_clean['Reserved'] != 'NOT RESERVED'\n",
    "    \n",
    "    # Add source identifier\n",
    "    df_clean['Source'] = 'Supplier2'\n",
    "    \n",
    "    # Standardize column names for consistency\n",
    "    rename_map = {\n",
    "        'Thickness (mm)': 'Thickness_mm',\n",
    "        'Width (mm)': 'Width_mm',\n",
    "        'Weight (kg)': 'Weight_kg'\n",
    "    }\n",
    "    df_clean.rename(columns=rename_map, inplace=True)\n",
    "    \n",
    "    # Since supplier2 doesn't have thickness/width, we'll set them as NaN\n",
    "    df_clean['Thickness_mm'] = np.nan\n",
    "    df_clean['Width_mm'] = np.nan\n",
    "    df_clean['Quality'] = np.nan  # No quality information in supplier2\n",
    "    \n",
    "    # Add missing technical properties as NaN\n",
    "    df_clean['RP02'] = np.nan\n",
    "    df_clean['RM'] = np.nan\n",
    "    df_clean['AG'] = np.nan\n",
    "    df_clean['AI'] = np.nan\n",
    "    \n",
    "    # Reorder and select columns to match supplier1 structure\n",
    "    column_order = ['Source', 'Grade', 'Quality', 'Finish',\n",
    "                   'Thickness_mm', 'Width_mm', 'Weight_kg',\n",
    "                   'Quantity', 'Description', 'RP02', 'RM', 'AG', 'AI',\n",
    "                   'Article ID', 'Coating', 'Reserved']\n",
    "    \n",
    "    df_clean = df_clean[column_order]\n",
    "    \n",
    "    return df_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bb3688cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(df1_clean, df2_clean):\n",
    "    \"\"\"\n",
    "    Merge the two cleaned datasets into a unified inventory dataset.\n",
    "    \n",
    "    Assumptions:\n",
    "    - Both datasets represent different inventory items (no duplicates between them)\n",
    "    - Union operation (concatenate all rows)\n",
    "    - Preserve all columns, filling NaN where data is not available\n",
    "    \"\"\"\n",
    "\n",
    "    # Get unique columns from each dataset\n",
    "    unique_cols1 = list(set(df1_clean.columns) - set(df2_clean.columns))\n",
    "    unique_cols2 = list(set(df2_clean.columns) - set(df1_clean.columns))\n",
    "    \n",
    "    # Add missing columns to each dataframe with NaN values\n",
    "    for col in unique_cols2:\n",
    "        df1_clean[col] = np.nan\n",
    "    \n",
    "    for col in unique_cols1:\n",
    "        df2_clean[col] = np.nan\n",
    "    \n",
    "    # Ensure same column order\n",
    "    all_columns = ['Source', 'Grade', 'Quality', 'Finish', 'Thickness_mm', \n",
    "                  'Width_mm', 'Weight_kg', 'Quantity', 'Description',\n",
    "                  'RP02', 'RM', 'AG', 'AI', 'Article ID', 'Coating', 'Reserved']\n",
    "    \n",
    "    df1_clean = df1_clean[all_columns]\n",
    "    df2_clean = df2_clean[all_columns]\n",
    "    \n",
    "    # Concatenate the datasets\n",
    "    inventory_df = pd.concat([df1_clean, df2_clean], ignore_index=True)\n",
    "    \n",
    "    # Add a unique inventory ID\n",
    "    inventory_df.insert(0, 'Inventory_ID', range(1, len(inventory_df) + 1))\n",
    "    \n",
    "    # Sort by Source and Grade for better organization\n",
    "    inventory_df = inventory_df.sort_values(['Source', 'Grade'], ignore_index=True)\n",
    "    \n",
    "    # Update Inventory_ID after sorting\n",
    "    inventory_df['Inventory_ID'] = range(1, len(inventory_df) + 1)\n",
    "    \n",
    "    return inventory_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f085322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    supplier1_df, supplier2_df = load_data()\n",
    "    \n",
    "    # Cleaning, normalizing, and handling missing values\n",
    "    supplier1_clean = clean_supplier1(supplier1_df)\n",
    "    supplier2_clean = clean_supplier2(supplier2_df)\n",
    "    \n",
    "    # Merge datasets\n",
    "    print(\"\\nMerging datasets...\")\n",
    "    inventory_df = merge_datasets(supplier1_clean, supplier2_clean)\n",
    "    print(f\"Unified inventory dataset created: {inventory_df.shape}\")  \n",
    "\n",
    "    # Check datatypes\n",
    "    print(\"\\nColumn datatypes:\")\n",
    "    print(inventory_df.dtypes)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path = Path(\"../../results/inventory_dataset.csv\")\n",
    "    inventory_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nInventory dataset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "abc6b862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merging datasets...\n",
      "Unified inventory dataset created: (100, 17)\n",
      "\n",
      "Column datatypes:\n",
      "Inventory_ID      int64\n",
      "Source           object\n",
      "Grade            object\n",
      "Quality         float64\n",
      "Finish           object\n",
      "Thickness_mm    float64\n",
      "Width_mm        float64\n",
      "Weight_kg       float64\n",
      "Quantity        float64\n",
      "Description      object\n",
      "RP02            float64\n",
      "RM              float64\n",
      "AG              float64\n",
      "AI              float64\n",
      "Article ID      float64\n",
      "Coating          object\n",
      "Reserved         object\n",
      "dtype: object\n",
      "\n",
      "Inventory dataset saved to: ../../results/inventory_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    inventory_df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1a8b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
